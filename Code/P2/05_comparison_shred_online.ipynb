{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of SHRED models with different sensing strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "path_svd = './OfflineSVD/'\n",
    "idx_params, params, var_names, is_vector, fom_times, rescaling_snaps, Nmodes = pickle.load(open(path_svd+'msfr_p.uloff', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us recompute the scalers for the POD coefficients (better to implement a way to import them)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "v_POD = pickle.load(open(path_svd+'v_POD.svd', 'rb'))\n",
    "\n",
    "assert sum(Nmodes) == v_POD['train'].shape[2]\n",
    "\n",
    "vpod_scaler = MinMaxScaler()\n",
    "vpod_scaler.fit(v_POD['train'].reshape(-1, sum(Nmodes)))\n",
    "\n",
    "rescaled_v_POD = {\n",
    "    key: vpod_scaler.transform(v_POD[key].reshape(-1, sum(Nmodes))).reshape(v_POD[key].shape)\n",
    "    for key in list(v_POD.keys())\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us load the test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Out-Core': 10, 'Mobile Sensors': 5, 'Mobile Probes': 4}\n",
      "{'Out-Core': 3, 'Mobile Sensors': 3, 'Mobile Probes': 6}\n",
      "{'Out-Core': 221, 'Mobile Sensors': 221, 'Mobile Probes': 221}\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../../')\n",
    "\n",
    "from shred.processdata import Padding, TimeSeriesDataset\n",
    "import torch\n",
    "\n",
    "path_test_datasets = {\n",
    "    'Out-Core': 'Test_results/',\n",
    "    'Mobile Sensors': 'Test_results/MobileSensor/',    \n",
    "    'Mobile Probes': 'Test_results/MobileProbes/'\n",
    "}\n",
    "\n",
    "test_datasets = {\n",
    "    key: pickle.load(open(path_test_datasets[key]+'test_dataset.pkl', 'rb'))\n",
    "    for key in path_test_datasets.keys()\n",
    "}\n",
    "\n",
    "# They are all loaded, but the .Y of each time serie is actually the same!!!\n",
    "\n",
    "n_configurations = {\n",
    "    key: len(test_datasets[key])\n",
    "    for key in path_test_datasets.keys()\n",
    "}\n",
    "\n",
    "input_size = {\n",
    "    key: test_datasets[key][0].X.shape[-1]\n",
    "    for key in path_test_datasets.keys()\n",
    "}\n",
    "\n",
    "output_size = {\n",
    "    key: test_datasets[key][0].Y.shape[-1]\n",
    "    for key in path_test_datasets.keys()\n",
    "}\n",
    "\n",
    "print(n_configurations)\n",
    "print(input_size)\n",
    "print(output_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us load the SHRED models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_shreds = {\n",
    "    'Out-Core': 'SHRED/',\n",
    "    'Mobile Sensors': 'SHRED/MobileSensor/',\n",
    "    'Mobile Probes': 'SHRED/MobileProbes/',\n",
    "}\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else ('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "\n",
    "measured_field = 3\n",
    "\n",
    "from shred.models import SHRED\n",
    "shred_models = dict()\n",
    "\n",
    "for key in path_shreds.keys():\n",
    "    shred_models[key] = list()\n",
    "    for kk in range(n_configurations[key]):\n",
    "        shred_models[key].append(\n",
    "            SHRED( input_size[key], output_size[key], \n",
    "            hidden_size = 64, hidden_layers = 2, decoder_sizes = [350, 400], dropout = 0.1).to(device)\n",
    "            )\n",
    "        \n",
    "        if key == 'Out-Core':\n",
    "            path_shred_mod = path_shreds[key]+'trained_config'+str(kk)+'_measuring_'+str(input_size[key])+'sens_'+var_names[measured_field]+'.shred'\n",
    "        elif key == 'Mobile Sensors':\n",
    "            path_shred_mod = path_shreds[key]+'trained_config'+str(kk)+'_measuring_'+str(input_size[key]/2)+'probes.shred'\n",
    "        elif key == 'Mobile Probes':\n",
    "            path_shred_mod = path_shreds[key]+'trained_config'+str(kk)+'_measuring_'+str(input_size[key])+'probes.shred'\n",
    "        \n",
    "        shred_models[key][kk].load_state_dict(\n",
    "            torch.load(path_shred_mod,map_location=device)\n",
    "            )\n",
    "        \n",
    "        shred_models[key][kk].freeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us evaluate the output of the SHRED models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out-Core\n",
      "Mean relative SHRED prediction error on POD coeffs: 3.00%.\n",
      "Std  relative SHRED prediction error on POD coeffs: 0.90%.\n",
      "-------------------------\n",
      "Mobile Sensors\n",
      "Mean relative SHRED prediction error on POD coeffs: 3.96%.\n",
      "Std  relative SHRED prediction error on POD coeffs: 2.17%.\n",
      "-------------------------\n",
      "Mobile Probes\n",
      "Mean relative SHRED prediction error on POD coeffs: 7.23%.\n",
      "Std  relative SHRED prediction error on POD coeffs: 3.40%.\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "from shred.processdata import num2p, mre\n",
    "\n",
    "reshaped_Ytest_hat = dict()\n",
    "\n",
    "for key in path_shreds.keys():\n",
    "    Ytest_POD_hat = torch.stack([shred_models[key][kk](test_datasets[key][kk].X) for kk in range(n_configurations[key])], dim=0)\n",
    "\n",
    "    Ytest_POD_pred = {\n",
    "        'mean': Ytest_POD_hat.mean(axis=0),\n",
    "        'std':  Ytest_POD_hat.std(axis=0) / np.sqrt(n_configurations[key])\n",
    "    }\n",
    "\n",
    "    # The test data are independent on the configurations of the sensors\n",
    "    print(key)\n",
    "    print(\"Mean relative SHRED prediction error on POD coeffs: %s.\" % num2p(mre(test_datasets[key][-1].Y, Ytest_POD_pred['mean'])))\n",
    "    print(\"Std  relative SHRED prediction error on POD coeffs: %s.\" % num2p((Ytest_POD_pred['std'].pow(2).sum(axis = -1).sqrt() / (test_datasets[key][-1].Y).pow(2).sum(axis = -1).sqrt()).mean()))\n",
    "    print('-------------------------')\n",
    "\n",
    "    reshaped_Ytest_hat[key] = {\n",
    "                            'mean': Ytest_POD_pred['mean'].cpu().detach().numpy().reshape(len(idx_params['test']), len(fom_times), output_size[key]),\n",
    "                            'std':  Ytest_POD_pred['std'].cpu().detach().numpy().reshape(len(idx_params['test']), len(fom_times), output_size[key])\n",
    "                         }\n",
    "    \n",
    "reshaped_Ytest = test_datasets['Out-Core'][-1].Y.cpu().detach().numpy().reshape(len(idx_params['test']), len(fom_times), output_size['Out-Core'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us decode to the high-dimensional space and compute the relative reconstruction error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing errors for Out-Core\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing error for U:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output as clc\n",
    "\n",
    "path_snaps = '../../NuSHRED_Datasets/D2/'\n",
    "\n",
    "compute_errors = True\n",
    "if compute_errors:\n",
    "    ave_rel_errors = dict()\n",
    "\n",
    "    for key in path_shreds.keys():\n",
    "\n",
    "        print('Computing errors for '+key)\n",
    "\n",
    "        ave_rel_errors[key] = np.zeros((len(var_names), len(idx_params['test']), len(fom_times)))\n",
    "\n",
    "        for field_i, field in enumerate(var_names):\n",
    "            idx_to_rec = np.arange(sum(Nmodes[:field_i]),  sum(Nmodes[:field_i+1]),  1, dtype=int)\n",
    "\n",
    "            # Load compressed dataset\n",
    "            u_data  = pickle.load(open(path_snaps + f'CompressedDataset/pod_basis_{field}.svd', 'rb'))\n",
    "            s_data  = pickle.load(open(path_snaps + f'CompressedDataset/sing_vals_{field}.svd', 'rb'))\n",
    "            vh_data = pickle.load(open(path_snaps + f'CompressedDataset/v_POD_all_fields.svd', 'rb'))[field]\n",
    "\n",
    "            for param_to_recon in tqdm(range(len(idx_params['test'])), 'Computing error for '+field):\n",
    "                fom = u_data @ s_data @ vh_data[idx_params['test'][param_to_recon]].T\n",
    "\n",
    "                u_svd = pickle.load(open(path_svd+'pod_basis_'+field+'.svd', 'rb'))\n",
    "                s_svd = pickle.load(open(path_svd+'sing_vals_'+field+'.svd', 'rb'))\n",
    "\n",
    "                _tmp_mean_v = vpod_scaler.inverse_transform(reshaped_Ytest_hat[key]['mean'][:,:,:-1].reshape(-1, sum(Nmodes))).reshape(reshaped_Ytest_hat[key]['mean'][:,:,:-1].shape)\n",
    "                recon     = u_svd @ np.diag(s_svd) @ _tmp_mean_v[param_to_recon, :, idx_to_rec]\n",
    "        \n",
    "                ave_rel_errors[key][field_i, param_to_recon, :] = np.linalg.norm(fom - recon, axis = 0) / np.linalg.norm(fom, axis = 0)\n",
    "\n",
    "                del fom, recon\n",
    "        clc()\n",
    "        \n",
    "    # Save the average relative errors\n",
    "    pickle.dump(ave_rel_errors, open('Test_results/comparison_ave_rel_errors.pkl', 'wb'))\n",
    "else:\n",
    "    ave_rel_errors = pickle.load(open(path_test_datasets['Out-Core']+'ave_rel_errors.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us define latex variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tex_var_names = [r'\\mathbf{u}', 'T', '\\Phi']\n",
    "energy_groups = 6\n",
    "tex_var_names.extend([r'\\phi_'+str(g+1) for g in range(energy_groups)])\n",
    "\n",
    "prec_groups = 8\n",
    "tex_var_names.extend([r'c_'+str(g+1) for g in range(prec_groups)])\n",
    "\n",
    "tex_var_names.extend(['p', r'p_{\\text{rgh}}', r'\\kappa', r'\\nu_t', \"q'''\"])\n",
    "\n",
    "assert len(tex_var_names) == len(var_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us create a table for the errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Out-Core</th>\n",
       "      <th>Mobile Sensors</th>\n",
       "      <th>Mobile Probes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>\\mathbf{u}</th>\n",
       "      <td>0.001563</td>\n",
       "      <td>0.008265</td>\n",
       "      <td>0.004867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T</th>\n",
       "      <td>0.012784</td>\n",
       "      <td>0.032119</td>\n",
       "      <td>0.022397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\\Phi</th>\n",
       "      <td>0.00479</td>\n",
       "      <td>0.065088</td>\n",
       "      <td>0.046097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\\phi_1</th>\n",
       "      <td>0.004775</td>\n",
       "      <td>0.065345</td>\n",
       "      <td>0.046468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\\phi_2</th>\n",
       "      <td>0.004774</td>\n",
       "      <td>0.065096</td>\n",
       "      <td>0.045981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\\phi_3</th>\n",
       "      <td>0.004783</td>\n",
       "      <td>0.06517</td>\n",
       "      <td>0.046364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\\phi_4</th>\n",
       "      <td>0.004786</td>\n",
       "      <td>0.064832</td>\n",
       "      <td>0.04614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\\phi_5</th>\n",
       "      <td>0.004781</td>\n",
       "      <td>0.065322</td>\n",
       "      <td>0.046122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\\phi_6</th>\n",
       "      <td>0.004785</td>\n",
       "      <td>0.065552</td>\n",
       "      <td>0.046094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_1</th>\n",
       "      <td>0.015392</td>\n",
       "      <td>0.048613</td>\n",
       "      <td>0.061521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_2</th>\n",
       "      <td>0.022622</td>\n",
       "      <td>0.083667</td>\n",
       "      <td>0.085808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_3</th>\n",
       "      <td>0.022593</td>\n",
       "      <td>0.084695</td>\n",
       "      <td>0.081943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_4</th>\n",
       "      <td>0.016723</td>\n",
       "      <td>0.069416</td>\n",
       "      <td>0.065179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_5</th>\n",
       "      <td>0.011724</td>\n",
       "      <td>0.057555</td>\n",
       "      <td>0.053272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_6</th>\n",
       "      <td>0.011728</td>\n",
       "      <td>0.057608</td>\n",
       "      <td>0.053352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_7</th>\n",
       "      <td>0.005791</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>0.045643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_8</th>\n",
       "      <td>0.005208</td>\n",
       "      <td>0.064017</td>\n",
       "      <td>0.046165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p</th>\n",
       "      <td>0.000632</td>\n",
       "      <td>0.006608</td>\n",
       "      <td>0.003634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_{\\text{rgh}}</th>\n",
       "      <td>0.004942</td>\n",
       "      <td>0.057614</td>\n",
       "      <td>0.030769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\\kappa</th>\n",
       "      <td>0.025396</td>\n",
       "      <td>0.211268</td>\n",
       "      <td>0.130273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\\nu_t</th>\n",
       "      <td>0.019659</td>\n",
       "      <td>0.082185</td>\n",
       "      <td>0.05764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q'''</th>\n",
       "      <td>0.004775</td>\n",
       "      <td>0.065199</td>\n",
       "      <td>0.045684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Out-Core Mobile Sensors Mobile Probes\n",
       "\\mathbf{u}      0.001563       0.008265      0.004867\n",
       "T               0.012784       0.032119      0.022397\n",
       "\\Phi             0.00479       0.065088      0.046097\n",
       "\\phi_1          0.004775       0.065345      0.046468\n",
       "\\phi_2          0.004774       0.065096      0.045981\n",
       "\\phi_3          0.004783        0.06517      0.046364\n",
       "\\phi_4          0.004786       0.064832       0.04614\n",
       "\\phi_5          0.004781       0.065322      0.046122\n",
       "\\phi_6          0.004785       0.065552      0.046094\n",
       "c_1             0.015392       0.048613      0.061521\n",
       "c_2             0.022622       0.083667      0.085808\n",
       "c_3             0.022593       0.084695      0.081943\n",
       "c_4             0.016723       0.069416      0.065179\n",
       "c_5             0.011724       0.057555      0.053272\n",
       "c_6             0.011728       0.057608      0.053352\n",
       "c_7             0.005791         0.0608      0.045643\n",
       "c_8             0.005208       0.064017      0.046165\n",
       "p               0.000632       0.006608      0.003634\n",
       "p_{\\text{rgh}}  0.004942       0.057614      0.030769\n",
       "\\kappa          0.025396       0.211268      0.130273\n",
       "\\nu_t           0.019659       0.082185       0.05764\n",
       "q'''            0.004775       0.065199      0.045684"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(columns=ave_rel_errors.keys(), index=tex_var_names)\n",
    "\n",
    "for key in ave_rel_errors.keys():\n",
    "    for field_i, field in enumerate(tex_var_names):\n",
    "        df.loc[field, key] = ave_rel_errors[key][field_i].mean()\n",
    "\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
